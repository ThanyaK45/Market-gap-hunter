import os
import requests
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
import osmnx as ox
import geopandas as gpd
import pandas as pd
from pydantic import BaseModel, validator
from typing import List, Dict
from dotenv import load_dotenv
from cache_manager import CacheManager
from history_manager import HistoryManager

try:
    import google.genai as genai
    USING_NEW_GENAI = True
except ImportError:
    import google.generativeai as genai
    USING_NEW_GENAI = False

# --- 1. LOAD ENVIRONMENT VARIABLES ---
load_dotenv()

# --- 2. SETUP APP ---
app = FastAPI(title="Market Gap Hunter API V2")

# Initialize Cache Manager
cache = CacheManager(cache_dir="cache", ttl_hours=24)

# Initialize History Manager
history = HistoryManager(history_file="analysis_history.json")

# Security: Load API Key from environment
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    raise ValueError("‚ùå GOOGLE_API_KEY not found in environment variables!")

# Configure Gemini API
if USING_NEW_GENAI:
    client = genai.Client(api_key=GOOGLE_API_KEY)
    print("‚úÖ Using new google.genai package")
else:
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
    print("‚ö†Ô∏è Using deprecated google.generativeai package")

# Rate Limiting
limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# CORS Configuration
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "http://localhost:5173,http://127.0.0.1:5173").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 3. CONFIGURATION ---
BUSINESS_MAPPINGS = {
    "Cafe": {"tags": {"amenity": "cafe"}},
    "Restaurant": {"tags": {"amenity": "restaurant"}},
    "Bar/Pub": {"tags": {"amenity": ["bar", "pub"]}},
    "Convenience Store": {"tags": {"shop": "convenience"}},
    "Pharmacy": {"tags": {"amenity": "pharmacy"}},
    "Gym/Fitness": {"tags": {"leisure": "fitness_centre"}},
    "Coworking Space": {"tags": {"amenity": "coworking_space"}},
}

# --- 4. PYDANTIC MODELS WITH VALIDATION ---
class AnalyzeRequest(BaseModel):
    lat: float
    lon: float
    business_type: str
    radius: int = 1000

    @validator('lat')
    def validate_lat(cls, v):
        if not -90 <= v <= 90:
            raise ValueError('Latitude must be between -90 and 90')
        return v
    
    @validator('lon')
    def validate_lon(cls, v):
        if not -180 <= v <= 180:
            raise ValueError('Longitude must be between -180 and 180')
        return v
    
    @validator('radius')
    def validate_radius(cls, v):
        if not 100 <= v <= 5000:
            raise ValueError('Radius must be between 100 and 5000 meters')
        return v
    
    @validator('business_type')
    def validate_business_type(cls, v):
        if v not in BUSINESS_MAPPINGS:
            raise ValueError(f'Business type must be one of: {list(BUSINESS_MAPPINGS.keys())}')
        return v

class AIRequest(BaseModel):
    business_type: str
    score: float
    supply_count: int
    demand_count: int
    demand_breakdown: dict
    growth_status: str

# --- 4. HELPER FUNCTIONS ---
def create_ai_prompt(data: AIRequest) -> str:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö AI"""
    return f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏≥‡πÄ‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á (Business Consultant)
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏•‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î "{data.business_type}" ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

- Opportunity Score: {data.score} (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î‡∏°‡∏≤‡∏Å ‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á‡∏ô‡πâ‡∏≠‡∏¢)
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á‡πÉ‡∏ô‡∏£‡∏±‡∏®‡∏°‡∏µ 1 ‡∏Å‡∏°.: {data.supply_count} ‡∏£‡πâ‡∏≤‡∏ô
- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏î‡∏π‡∏î‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ (Demand): {data.demand_count} ‡πÅ‡∏´‡πà‡∏á
- ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: {data.demand_breakdown}
- ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà): {data.growth_status}

‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö (‡∏Ç‡∏≠‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏Å‡∏£‡∏∞‡∏ä‡∏±‡∏ö ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡∏™‡πÑ‡∏ï‡∏•‡πå‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û):

üéØ **‡∏Ñ‡∏≥‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô:** (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡πà‡∏≤‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏°‡∏≤‡∏Å / ‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á / ‡∏ï‡∏•‡∏≤‡∏î‡∏≠‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏• 1 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î

üí™ **‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏Ç‡∏≠‡∏á‡∏ó‡∏≥‡πÄ‡∏•‡∏ô‡∏µ‡πâ:** (1 ‡∏Ç‡πâ‡∏≠)

‚ö†Ô∏è **‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ß‡∏±‡∏á:** (1 ‡∏Ç‡πâ‡∏≠)

üí° **‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 1 ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î ‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏£‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ)

‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÉ‡∏™‡πà‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ ** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠"""

# --- 5. API ENDPOINTS ---

@app.get("/")
def root():
    """Health check endpoint"""
    return {
        "status": "online",
        "service": "Market Gap Hunter API V2",
        "version": "2.0.0"
    }

@app.get("/cache/stats")
def cache_stats():
    """Get cache statistics"""
    cache_files = list(cache.cache_dir.glob("*.json"))
    return {
        "total_cached_items": len(cache_files),
        "cache_dir": str(cache.cache_dir),
        "ttl_hours": cache.ttl.total_seconds() / 3600
    }

@app.post("/cache/clear")
def clear_cache(expired_only: bool = True):
    """Clear cache (expired only by default)"""
    if expired_only:
        cleared = cache.clear_expired()
        return {"message": f"Cleared {cleared} expired cache files"}
    else:
        cleared = cache.clear_all()
        return {"message": f"Cleared all {cleared} cache files"}

@app.get("/history")
def get_history(limit: int = 10, business_type: str = None):
    """Get analysis history"""
    return history.get_history(limit=limit, business_type=business_type)

@app.get("/history/location")
def get_location_history(lat: float, lon: float, tolerance: float = 0.01):
    """Get history for specific location"""
    return history.get_location_history(lat=lat, lon=lon, tolerance=tolerance)

@app.get("/history/stats")
def get_history_stats():
    """Get history statistics"""
    return history.get_statistics()

@app.delete("/history")
def clear_history():
    """Clear all history"""
    cleared = history.clear_history()
    return {"message": f"Cleared {cleared} history entries"}

@app.get("/search")
@limiter.limit("20/minute")
def search_place(request: Request, query: str):
    print(f"üîé Searching for: {query}")
    try:
        # ‡πÉ‡∏ä‡πâ OSMnx ‡∏´‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠
        lat, lon = ox.geocode(query)
        return {"lat": lat, "lon": lon, "name": query}
    except Exception as e:
        raise HTTPException(status_code=404, detail=f"Location not found: {e}")

@app.get("/autocomplete")
@limiter.limit("30/minute")
def autocomplete(request: Request, query: str, country: str = ""):
    print(f"üîé Autocomplete: {query} in {country}")
    
    url = "https://nominatim.openstreetmap.org/search"
    
    params = {
        "q": query,
        "format": "json",
        "limit": 20,  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≠‡∏á‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
        "addressdetails": 1,
        "extratags": 1,  # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
    }
    
    if country:
        params["countrycodes"] = country

    headers = {
        "User-Agent": "MarketGapHunter_StudentProject_V2/1.0 (thanyatle2004@gmail.com)",
        "Referer": "http://127.0.0.1:8000"
    }
    
    try:
        response = requests.get(url, params=params, headers=headers)
        
        if response.status_code != 200:
            print(f"‚ùå Nominatim Error! Status: {response.status_code}")
            return []

        data = response.json()
        
        # ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (Relevance Scoring)
        scored_results = []
        
        for item in data:
            score = 0
            place_type = item.get("type", "")
            place_class = item.get("class", "")
            importance = float(item.get("importance", 0))
            
            # ‡∏Å‡∏£‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
            # 1. ‡∏Ç‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏±‡πâ‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
            if place_class == "boundary" and place_type == "administrative":
                admin_level = item.get("address", {}).get("country")
                if admin_level and len(item["display_name"].split(",")) <= 1:
                    continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
            
            # 2. ‡∏Ç‡πâ‡∏≤‡∏°‡∏ó‡∏ß‡∏µ‡∏õ/‡∏°‡∏´‡∏≤‡∏™‡∏°‡∏∏‡∏ó‡∏£
            if place_class in ["natural", "waterway"] and place_type in ["sea", "ocean", "continent"]:
                continue
            
            # ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà (‡∏¢‡∏¥‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ)
            priority_map = {
                # POI ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î)
                "amenity": 100,
                "shop": 95,
                "tourism": 90,
                "leisure": 85,
                "building": 80,
                
                # ‡∏ñ‡∏ô‡∏ô/‡∏ã‡∏≠‡∏¢ (‡∏Ñ‡πà‡∏≠‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á)
                "highway": 70,
                
                # ‡∏¢‡πà‡∏≤‡∏ô/‡πÄ‡∏Ç‡∏ï (‡∏Å‡∏•‡∏≤‡∏á‡πÜ)
                "place": {
                    "neighbourhood": 60,
                    "suburb": 55,
                    "quarter": 58,
                    "city_block": 62,
                    "hamlet": 50,
                    "village": 45,
                    "town": 40,
                    "city": 35,
                    "state": 10,
                    "country": 5
                },
                
                # ‡πÄ‡∏Ç‡∏ï‡∏Å‡∏≤‡∏£‡∏õ‡∏Å‡∏Ñ‡∏£‡∏≠‡∏á (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥)
                "boundary": 20,
            }
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
            if place_class in priority_map:
                if isinstance(priority_map[place_class], dict):
                    score = priority_map[place_class].get(place_type, 30)
                else:
                    score = priority_map[place_class]
            else:
                score = 40  # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
            
            # ‡πÇ‡∏ö‡∏ô‡∏±‡∏™‡∏à‡∏≤‡∏Å importance (‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà Nominatim ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÉ‡∏´‡πâ)
            score += importance * 20
            
            # ‡πÇ‡∏ö‡∏ô‡∏±‡∏™‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (case-insensitive)
            display_name_lower = item["display_name"].lower()
            query_lower = query.lower()
            
            if display_name_lower.startswith(query_lower):
                score += 30  # ‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            elif query_lower in display_name_lower.split(",")[0].lower():
                score += 20  # ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠
            elif query_lower in display_name_lower:
                score += 10  # ‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô‡∏™‡∏±‡∏Å‡πÅ‡∏´‡πà‡∏á‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
            
            scored_results.append({
                "display_name": item["display_name"],
                "lat": float(item["lat"]),
                "lon": float(item["lon"]),
                "score": score,
                "type": place_type,
                "class": place_class
            })
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡∏°‡∏≤‡∏Å‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢
        scored_results.sort(key=lambda x: x["score"], reverse=True)
        
        # ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÅ‡∏Ñ‡πà 8 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á score ‡πÑ‡∏õ‡πÉ‡∏´‡πâ frontend)
        suggestions = [
            {
                "display_name": r["display_name"],
                "lat": r["lat"],
                "lon": r["lon"]
            }
            for r in scored_results[:8]
        ]
        
        return suggestions
        
    except Exception as e:
        print(f"Error autocomplete: {e}")
        return []

@app.post("/analyze")
@limiter.limit("10/minute")
async def analyze_market(request: Request, req: AnalyzeRequest):
    print(f"üåç Received Request: {req.business_type} at ({req.lat}, {req.lon})")
    
    # Check cache first
    cache_key_params = {
        "lat": round(req.lat, 4),  # Round to reduce cache misses
        "lon": round(req.lon, 4),
        "business_type": req.business_type,
        "radius": req.radius
    }
    
    cached_result = cache.get(**cache_key_params)
    if cached_result:
        print("‚úÖ Returning cached result")
        return cached_result
    
    if req.business_type not in BUSINESS_MAPPINGS:
        raise HTTPException(status_code=400, detail="Business type not supported")
    
    center_point = (req.lat, req.lon)
    supply_tags = BUSINESS_MAPPINGS[req.business_type]["tags"]
    
    # A. Fetch Supply
    supply_points = []
    num_supply = 0
    try:
        supply_gdf = ox.features_from_point(center_point, tags=supply_tags, dist=req.radius)
        if not supply_gdf.empty:
            supply_gdf['centroid'] = supply_gdf.geometry.centroid
            for p, row in zip(supply_gdf['centroid'], supply_gdf.to_dict('records')):
                name = row.get('name', 'Unknown')
                if pd.isna(name): name = "Unknown"
                if pd.notna(p.y) and pd.notna(p.x):
                    supply_points.append({"lat": p.y, "lon": p.x, "name": name})
            num_supply = len(supply_points)
    except Exception as e:
        print(f"Error supply: {e}")

    # B. Fetch Demand & Breakdown
    demand_tags_map = {
        'office': 'Office',
        'school': 'Students',
        'university': 'Students',
        'college': 'Students',
        'apartments': 'Residential',
        'condominium': 'Residential',
        'residential': 'Residential',
        'station': 'Transport'
    }
    
    query_tags = {
        'office': True,
        'amenity': ['school', 'university', 'college'],
        'building': ['apartments', 'condominium', 'residential'],
        'public_transport': ['station']
    }

    demand_points = []
    demand_breakdown = {"Office": 0, "Students": 0, "Residential": 0, "Transport": 0}
    
    try:
        demand_gdf = ox.features_from_point(center_point, tags=query_tags, dist=req.radius)
        if not demand_gdf.empty:
            # Loop ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° (Segmentation)
            for _, row in demand_gdf.iterrows():
                assigned = False
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ô‡∏µ‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö tag ‡πÑ‡∏´‡∏ô‡πÉ‡∏ô map
                for col in demand_gdf.columns:
                    val = str(row.get(col))
                    if val in demand_tags_map:
                        group = demand_tags_map[val]
                        demand_breakdown[group] += 1
                        assigned = True
                        break
                if not assigned: # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÇ‡∏¢‡∏ô‡∏•‡∏á Residential (‡∏Ñ‡πà‡∏≤ Default)
                    demand_breakdown["Residential"] += 1
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏¥‡∏Å‡∏±‡∏î
            demand_gdf['centroid'] = demand_gdf.geometry.centroid
            if len(demand_gdf) > 1000: demand_gdf = demand_gdf.sample(1000)
            demand_points = [{"lat": p.y, "lon": p.x} for p in demand_gdf['centroid']]
            
    except Exception as e:
        print(f"Error demand: {e}")

    # C. Future Growth (Construction Sites)
    growth_status = "‡∏ó‡∏£‡∏á‡∏ï‡∏±‡∏ß üèôÔ∏è"
    cons_count = 0
    try:
        cons_gdf = ox.features_from_point(center_point, tags={'landuse': 'construction'}, dist=req.radius)
        cons_count = len(cons_gdf)
        if cons_count > 5: growth_status = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏π‡∏°‡∏™‡∏∏‡∏î‡πÜ üöÄ"
        elif cons_count > 2: growth_status = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï üìà"
    except:
        pass

    # D. Calculate Score & Prepare Result
    num_demand = len(demand_points)
    divisor = num_supply if num_supply > 0 else 1
    score = round(num_demand / divisor, 2)

    if num_supply == 0 and num_demand > 0:
        verdict = "‡∏ï‡∏•‡∏≤‡∏î‡πÑ‡∏£‡πâ‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á (‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å)"
        color = "#2980b9" # Blue
    elif score > 5.0:
        verdict = "‡∏®‡∏±‡∏Å‡∏¢‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á (‡∏ô‡πà‡∏≤‡∏•‡∏á‡∏ó‡∏∏‡∏ô)"
        color = "#27ae60" # Green
    elif score > 2.0:
        verdict = "‡∏ï‡∏•‡∏≤‡∏î‡∏™‡∏°‡∏î‡∏∏‡∏• (‡∏û‡∏≠‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô‡πÑ‡∏î‡πâ)"
        color = "#f39c12" # Orange
    else:
        verdict = "‡∏ï‡∏•‡∏≤‡∏î‡∏≠‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß (Red Ocean)"
        color = "#c0392b" # Red

    result = {
        "score": score,
        "verdict": verdict,
        "verdict_color": color,
        "supply_count": num_supply,
        "demand_count": num_demand,
        "demand_breakdown": demand_breakdown,
        "growth_status": growth_status,
        "construction_count": cons_count,
        "supply_points": supply_points,
        "demand_points": demand_points
    }
    
    # Save to cache before returning
    cache.set(result, **cache_key_params)
    
    # Save to history
    history.add_analysis(
        lat=req.lat,
        lon=req.lon,
        business_type=req.business_type,
        radius=req.radius,
        result=result
    )
    
    return result

@app.post("/ask-ai")
@limiter.limit("5/minute")
async def ask_ai_consultant(request: Request, data: AIRequest):
    print("ü§ñ AI is analyzing...")
    
    prompt = create_ai_prompt(data)
    
    try:
        if USING_NEW_GENAI:
            response = client.models.generate_content(
                model='gemini-2.0-flash-exp',
                contents=prompt
            )
            analysis_text = response.text
        else:
            response = model.generate_content(prompt)
            analysis_text = response.text
            
        return {"analysis": analysis_text}
    except Exception as e:
        print(f"AI Error: {e}")
        raise HTTPException(status_code=500, detail=f"AI Service Error: {str(e)}")

# Streaming AI endpoint
from fastapi.responses import StreamingResponse

@app.post("/ask-ai-stream")
@limiter.limit("5/minute")
async def ask_ai_stream(request: Request, data: AIRequest):
    print("ü§ñ AI is analyzing (streaming)...")
    
    prompt = create_ai_prompt(data)
    
    async def generate():
        try:
            if USING_NEW_GENAI:
                response = client.models.generate_content(
                    model='gemini-2.0-flash-exp',
                    contents=prompt,
                    config={'response_modalities': ['TEXT']}
                )
                yield response.text
            else:
                response = model.generate_content(prompt, stream=True)
                for chunk in response:
                    if chunk.text:
                        yield chunk.text
        except Exception as e:
            print(f"AI Streaming Error: {e}")
            yield f"Error: {str(e)}"
    
    return StreamingResponse(generate(), media_type="text/plain")
